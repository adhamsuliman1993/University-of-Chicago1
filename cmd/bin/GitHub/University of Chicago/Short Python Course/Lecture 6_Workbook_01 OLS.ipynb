{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "# 1 OLS Regression with `statsmodels`\n",
    "\n",
    "* to install `conda install statsmodels` or `pip install statsmodels`    \n",
    "* uses package <a href = 'http://patsy.readthedocs.io/en/latest/'>pasty</a> which allows passing **R** style formulas.  \n",
    "* contains a large number of modules for statistical testing and model estimation <a href= 'http://www.statsmodels.org/stable/py-modindex.html'>Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 1.1 data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5123</td>\n",
       "      <td>-122.337</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3684</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date    price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000   221900         3       1.00         1180   \n",
       "1  6414100192  20141209T000000   538000         3       2.25         2570   \n",
       "2  5631500400  20150225T000000   180000         2       1.00          770   \n",
       "3  2487200875  20141209T000000   604000         4       3.00         1960   \n",
       "4  1954400510  20150218T000000   510000         3       2.00         1680   \n",
       "5  7237550310  20140512T000000  1225000         4       4.50         5420   \n",
       "6  1321400060  20140627T000000   257500         3       2.25         1715   \n",
       "7  2008000270  20150115T000000   291850         3       1.50         1060   \n",
       "8  2414600126  20150415T000000   229500         3       1.00         1780   \n",
       "9  3793500160  20150312T000000   323000         3       2.50         1890   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "5    101930     1.0           0     0     ...         11        3890   \n",
       "6      6819     2.0           0     0     ...          7        1715   \n",
       "7      9711     1.0           0     0     ...          7        1060   \n",
       "8      7470     1.0           0     0     ...          7        1050   \n",
       "9      6560     2.0           0     0     ...          7        1890   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "5           1530      2001             0    98053  47.6561 -122.005   \n",
       "6              0      1995             0    98003  47.3097 -122.327   \n",
       "7              0      1963             0    98198  47.4095 -122.315   \n",
       "8            730      1960             0    98146  47.5123 -122.337   \n",
       "9              0      2003             0    98038  47.3684 -122.031   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "5           4760      101930  \n",
       "6           2238        6819  \n",
       "7           1650        9711  \n",
       "8           1780        8113  \n",
       "9           2390        7570  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'C:/Users/u353822/Documents/Git/bin/GitHub/University of Chicago/Short Python Course/homes.csv'\n",
    "dataset = pd.read_csv(filepath, header = 0, sep = ',')\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.id = dataset.id.astype('category')\n",
    "dataset.waterfront = dataset.waterfront.astype('category')\n",
    "dataset.view = dataset.view.astype('category')\n",
    "dataset.grade = dataset.grade.astype('category')\n",
    "dataset.condition = dataset.condition.astype('category')\n",
    "dataset = dataset.drop(['zipcode'], axis = 1)\n",
    "dataset = dataset.drop(['sqft_living15'], axis = 1)\n",
    "dataset = dataset.drop(['sqft_lot15'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* this dataset is collected in 2015 and the latest year for a home build or renovated is 2015.      \n",
    "* for the columns `yr_built` and `yr_renovated` to keep them as numeric variables it is better to convert the values in these column in the form of an offset from 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.yr_built = [2015 - yr for yr in dataset.yr_built]\n",
    "\n",
    "dataset.yr_renovated = [2015 - yr if yr != 0 else yr for yr in dataset.yr_renovated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>in two steps using `map()` and `lambda()` operator convert the date column into a numpy `datetime64`   \n",
    "how do you think you can go about this task given a date variable with `20141013T000000` format?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code\n",
    "new_date = list(map(lambda x: x.split('T')[0], dataset.date))\n",
    "new_date = list(map(lambda x: np.datetime64('-'.join([x[0:4],]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#skipped code\n",
    "#new_date = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.date = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "* convert the `id` column a dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.set_index(['id'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style=\"color:blue\">rearrange the columns in the dataset to push the four cateorical variables to the very end.</span>    \n",
    "\n",
    "\n",
    "* in addition purge the last two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code\n",
    "#new_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "## 1.2 pair plots and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this takes a long time to process\n",
    "#sns.pairplot(dataset.iloc[:,1:11], diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.iloc[:,1:11].corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.set(style=\"white\") # options include white, dark, whitegrid, darkgrid, ticks\n",
    "sns.heatmap(corr, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there is a strong positive correlation between `sqft_above` (Square footage of house apart from basement) and `sqrt_living`\n",
    "(Square footage of the living room) at 0.876597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['sqft_above'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "## 1.3 model estimation and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split(*array, test_size = .25, train_size, random_state, shuffle = True)`\n",
    "\n",
    "test_size/train_size: \n",
    "        * float => proportion of data      \n",
    "        * int => absolute number of observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train, d_test = train_test_split(dataset, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train.shape, d_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "* we shall perform a **hedonic regression** using the homes dataset after cleaning.\n",
    "\n",
    "* for this we do not require the `date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train = d_train.drop(['date'], axis = 1)\n",
    "d_test = d_test.drop(['date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "statsmodels requires that the function call be passed in be a string in the format `output ~ input_! + input_2 + ... input_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "function_call = 'price ~ ' + ' + '.join(d_train.columns[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod = smf.ols(function_call , data = d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = lmod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print('F statistic:   ',results.fvalue)\n",
    "print('F stat pvalue: ',results.f_pvalue)\n",
    "print('r squared:     ',results.rsquared)\n",
    "print('r squared adj: ',results.rsquared_adj)\n",
    "print('residuals df:  ',results.df_resid)\n",
    "print('SST:           ',results.mse_total*(results.df_resid + results.df_model))\n",
    "print('SSE:           ',results.mse_resid*results.df_resid)\n",
    "print('SSM:           ',results.mse_model*results.df_model)\n",
    "print('resid std err: ',results.mse_resid**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.arange(d_train.shape[0]),results.resid, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results.fittedvalues, results.resid, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 1.4 model Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_pred = results.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mse_prediction = 1/(d_test.shape[0])*np.sum((lmod_pred - d_test.price)**2)\n",
    "mse_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<span style='color:blue'>what do you think about the value of MSE ?</span>\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "we can also calculate the `mean_squared_error` using the method with the same name from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = d_test.price, y_pred = lmod_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.kstest(results.resid, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(results.resid, bins = 100, fit = scipy.stats.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot(results.resid, dist = scipy.stats.norm ,fit = True, line='45')\n",
    "plt.axis([-5,5,-15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>can we do anything to make the residuals Gaussian ?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_1 = smf.ols(function_call_1, data = d_train)\n",
    "\n",
    "results_1 = lmod_1.fit()\n",
    "print(results_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print('F statistic:   ',results_1.fvalue)\n",
    "print('F stat pvalue: ',results_1.f_pvalue)\n",
    "print('r squared:     ',results_1.rsquared)\n",
    "print('r squared adj: ',results_1.rsquared_adj)\n",
    "print('residuals df:  ',results_1.df_resid)\n",
    "print('SST:           ',results_1.mse_total*(results.df_resid + results.df_model))\n",
    "print('SSE:           ',results_1.mse_resid*results.df_resid)\n",
    "print('SSM:           ',results_1.mse_model*results.df_model)\n",
    "print('resid std err: ',results_1.mse_resid**.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "`F statistic:    1151.65066416\n",
    "F stat pvalue:  0.0\n",
    "r squared:      0.651343773911\n",
    "r squared adj:  0.650778199823\n",
    "residuals df:   17261.0\n",
    "SST:            4789.71978586\n",
    "SSE:            1669.96562456\n",
    "SSM:            3119.7541613\n",
    "resid std err:  0.311043256005`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>first plot `results.resid` followed by `results_1.resid` vs `results_1.fittedvalues` (similar to the previous plots)      \n",
    "what do you think about the residuals? </spab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different plotting package\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "plot results.resid for a quick comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(d_train.shape[0]), results.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(d_train.shape[0]), results_1.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 700, plot_height = 400)\n",
    "p.scatter(results_1.fittedvalues, results_1.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_pred_1 = results_1.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mse_prediction = 1/(d_test.shape[0])*np.sum((lmod_pred_1 - np.log(d_test.price))**2)\n",
    "mse_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mse_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.kstest(results_1.resid, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(results_1.resid, bins = 100, fit = scipy.stats.norm, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig = sm.qqplot(results_1.resid, dist = scipy.stats.norm ,fit = True, line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* can we infer anything from the Jarque-Bera test of normality ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.jarque_bera(results_1.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* the Jarque-Bera test is a test for normality that is based on sample skewness and kurtosis with     \n",
    "`H0: the distribution is normal`       \n",
    "`H1: the distribution is not normal`.   \n",
    "\n",
    "\n",
    "\n",
    "* the calculated statistic $JB = \\frac{N}{6} \\bigg(S^2 + \\frac{(K-3)^2}{4} \\bigg)$   \n",
    "* with a sample size > 2000 the test statistic is compared to a $\\chi^2$ distribution with 2 degrees of freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# this is what a chi-square distribution with df=2 looks like\n",
    "np.random.seed(40)\n",
    "chisq_sim = np.random.chisquare(2, 20000)\n",
    "sns.distplot(chisq_sim, bins = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* despite the fact that the Jarque-Bera test is conclusive, and there is enough evidence to reject the null, the JB statistic went from 266387.882 to 121.22. However for a p-value to not reject the Null the JB statistic needs to approximately between 0 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "# 2 OLS Regression using `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* scikit learn does not ingest categorical variables passed into the method input. instead all categorical variable need to be processed prior to running the model estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.dtypes, dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 2.1 encoding categorical variables\n",
    "\n",
    "* `scikit-learn` does not automatically handle categorical variables.   \n",
    "* in order to use the `LinearRegression` module and other modules we have to encode all the categorical variable in dummy coding.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LabelEncoder` is the method that converts categorical non-numeric variables into numeric representation   \n",
    "`OneHotEncoder` is the method that converts numeric variables into dummy variable  \n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.unique(dataset.iloc[:,i], return_counts = True) for i in range(10,14)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have two catagorical variables starting at level `0` and two starting at level `1`\n",
    "\n",
    "hence these two variables require the use of `LabelEncoder` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "the following series of steps are often analogous for different methods of scikit-learn\n",
    "\n",
    "1- assign the method to a name space (creating an instance of that method)     \n",
    "**set the paramteres and arguments of the new instance method in this step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc = LabelEncoder()\n",
    "\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- apply the instance method `.fit` to ingest the data using the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.fit(dataset.condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - apply the instance method `.transform` to interpret the results and produce an output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.transform(dataset.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "steps 3 and 4 can often be combined together in a single expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.fit(dataset.condition).transform(dataset.condition).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(lbc_condition, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_grade = lbc.fit(dataset.grade).transform(dataset.grade).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_array = np.hstack([np.array(dataset.waterfront).reshape((-1,1)), \n",
    "                        np.array(dataset.view).reshape((-1,1)), \n",
    "                        lbc_condition, lbc_grade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_obj = enc.fit(categorical_array)\n",
    "\n",
    "cat_vars = fit_obj.transform(categorical_array).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "this is good.    \n",
    "\n",
    "however for the regression problem we the first dummy variable from every category to be removed in order to allow for correct calculation of an intercept \n",
    "\n",
    "how can we go about it ?\n",
    "\n",
    "display the instance methods and attributed of the `fit_obj` calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(fit_obj) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_obj.feature_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these indeces represent the first or every group of dummy variables corresponding to the 4 variables.      \n",
    "the last index is the total number of columns overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['view_'+str(i) for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ = ['waterfront1']+\\\n",
    "         ['view_'+str(i) for i in range(1,5)]+\\\n",
    "         ['con_'+str(i) for i in range(2,6)]+\\\n",
    "         ['g_'+str(i) for i in range(3,14)]\n",
    "names_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_clean = pd.DataFrame(np.delete(cat_vars, fit_obj.feature_indices_[:-1], 1), columns = names_)\n",
    "cat_var_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* drop the original categorical variables to substitute with the dummy data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset_skl = dataset.drop(['date'], axis = 1).reset_index(drop = True).copy()\n",
    "\n",
    "#both tables need to have the same index. \n",
    "#either drop index of dataset or assign its index value to vat_var_clean\n",
    "\n",
    "dataset_skl = dataset_skl.drop(['waterfront', 'view', 'grade', 'condition'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset_skl = pd.concat([dataset_skl, cat_var_clean], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_skl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "## 2.2 Model estimation and diagnistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# use the same seed to retrieve an indentical train/test split.\n",
    "d_train_skl, d_test_skl = train_test_split(dataset_skl, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model` takes an argument for the input and an argument for the output(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_x = d_train_skl.iloc[:,1:]\n",
    "train_y = np.log(d_train_skl.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "recall the steps from earlier: \n",
    "\n",
    "1- create an instance of the method and set the parameters and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression(fit_intercept = True, normalize = False, copy_X = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- apply the instsance method `.fit` using the variables or input and outpute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_fit = ols.fit(X = train_x, y = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results_1.params[0], ols.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "we can compare the coefficients from statsmodels `results` object and sklearn coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(results_1.params, columns = ['statsmodels']).sort_values(by = 'statsmodels').drop(['Intercept'], axis = 0)\n",
    "b = pd.DataFrame(ols_fit.coef_, columns = ['sklearn']).sort_values(by = 'sklearn').set_index(a.index)\n",
    "df = pd.concat([b,a], axis = 1).sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "* in order to obtain the fittedvalues and residuals we have to calculate these manually. \n",
    "\n",
    "$$\\begin{bmatrix} fitted\\ val1 \\\\ fitted\\ val2 \\\\ . \\\\ . \\\\ . \\\\ fitted\\ valN \\end{bmatrix} = intercept + \n",
    "\\begin{bmatrix} x_{1,1} & x_{1,2} & . . . & x_{1,m-1} & x_{1,m} \\\\ \n",
    "                x_{2,1} & \\ddots & . . . & x_{2,m-1} & x_{2,m} \\\\ \n",
    "                . & . & \\ddots & . & . \\\\ \n",
    "                . & . & . & \\ddots  & . \\\\ \n",
    "                x_{n-1,1} & x_{n-1,2} & . . . & x_{n-1,m-1} & x_{n-1,m} \\\\\n",
    "                x_{n,1} & x_{n,2} & . . . & x_{n,m-1} & x_{n,m} \n",
    "                \\end{bmatrix} \\times \\begin{bmatrix} \\theta_{bathrooms} \\\\ \\theta_{bedrooms} \\\\ . \\\\ \\theta_{grade[T.3]} \\\\ . \\\\ \\theta_{yr\\ renovated} \\end{bmatrix}$$\n",
    "                \n",
    "&nbsp;                \n",
    "\n",
    "$$Residuals = Output - Fitted\\ Values$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_fittedvalues = np.dot(train_x, np.array(ols.coef_).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_resids = train_y.values - ols_fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(train_x.shape[0]), ols_fittedvalues, color = 'peachpuff')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(ols_fittedvalues, ols_resids, color = 'peachpuff')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* the instance method `.score` of the fit object `ols` returns the coefficient of determination $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_rsq = ols.score(X = train_x, y = train_y)\n",
    "ols_rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly `fit.rank_` returns the degrees of freedom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deg_freedom = ols_fit.rank_\n",
    "deg_freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; \n",
    "\n",
    "$adj\\_r.squared$ can be calculated manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "n, k = train_x.shape[0], len(train_x.columns.values)\n",
    "n , k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "$adj\\_r.squared = 1 - \\bigg[\\frac{(1 - R^2)(n-1}{n-k-1}\\bigg] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_adj_rsq = 1 - ((1 - ols_rsq)*(n-1)/(n-k-1))\n",
    "ols_adj_rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "## 2.3 Model validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "test_x = d_test_skl.iloc[:,1:]\n",
    "test_y = np.log(d_test_skl.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "3- instead of `.transform()` the method `.predict()` takes the inputs of the test set and calculates a predicted output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_pred = ols_fit.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = test_y, y_pred = ols_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Addendum\n",
    "\n",
    "instead of using `OneHotEncoder()` the method `pandas.get_dummies()` allows us to convert a categorical variable into dummy variables and allows us to drop the first column by setting an argument within the method call.     \n",
    " \n",
    " \n",
    "since this is a pandas method it preserves the index of the original dataframe   \n",
    "\n",
    "using <U>dataset</U>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_waterfront = pd.get_dummies(dataset.waterfront, drop_first = True)\n",
    "pd_view = pd.get_dummies(dataset.view, drop_first = True)\n",
    "pd_condition = pd.get_dummies(dataset.condition, drop_first = True)\n",
    "pd_grade = pd.get_dummies(dataset.grade, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d = pd.concat([dataset.iloc[:,1:10], pd_waterfront, pd_view, pd_condition, pd_grade], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d.columns = dataset.columns[1:10].tolist() + names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d.head()"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
