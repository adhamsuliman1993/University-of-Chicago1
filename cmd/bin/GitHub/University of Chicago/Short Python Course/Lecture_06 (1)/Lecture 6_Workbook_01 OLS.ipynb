{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "# 1 OLS Regression with `statsmodels`\n",
    "\n",
    "* to install `conda install statsmodels` or `pip install statsmodels`    \n",
    "* uses package <a href = 'http://patsy.readthedocs.io/en/latest/'>pasty</a> which allows passing **R** style formulas.  \n",
    "* contains a large number of modules for statistical testing and model estimation <a href= 'http://www.statsmodels.org/stable/py-modindex.html'>Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 1.1 data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "filepath = 'data/homes.csv'\n",
    "dataset = pd.read_csv(filepath, header = 0, sep = ',')\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.id = dataset.id.astype('category')\n",
    "dataset.waterfront = dataset.waterfront.astype('category')\n",
    "dataset.view = dataset.view.astype('category')\n",
    "dataset.grade = dataset.grade.astype('category')\n",
    "dataset.condition = dataset.condition.astype('category')\n",
    "dataset = dataset.drop(['zipcode'], axis = 1)\n",
    "dataset = dataset.drop(['sqft_living15'], axis = 1)\n",
    "dataset = dataset.drop(['sqft_lot15'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* this dataset is collected in 2015 and the latest year for a home build or renovated is 2015.      \n",
    "* for the columns `yr_built` and `yr_renovated` to keep them as numeric variables it is better to convert the values in these column in the form of an offset from 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.yr_built = [2015 - yr for yr in dataset.yr_built]\n",
    "\n",
    "dataset.yr_renovated = [2015 - yr if yr != 0 else yr for yr in dataset.yr_renovated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>in two steps using `map()` and `lambda()` operator convert the date column into a numpy `datetime64`   \n",
    "how do you think you can go about this task given a date variable with `20141013T000000` format?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#skipped code\n",
    "#new_date = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.date = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "* convert the `id` column a dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.set_index(['id'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style=\"color:blue\">rearrange the columns in the dataset to push the four cateorical variables to the very end.</span>    \n",
    "\n",
    "\n",
    "* in addition purge the last two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code\n",
    "#new_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "## 1.2 pair plots and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this takes a long time to process\n",
    "#sns.pairplot(dataset.iloc[:,1:11], diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset.iloc[:,1:11].corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.set(style=\"white\") # options include white, dark, whitegrid, darkgrid, ticks\n",
    "sns.heatmap(corr, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there is a strong positive correlation between `sqft_above` (Square footage of house apart from basement) and `sqrt_living`\n",
    "(Square footage of the living room) at 0.876597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['sqft_above'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "## 1.3 model estimation and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split(*array, test_size = .25, train_size, random_state, shuffle = True)`\n",
    "\n",
    "test_size/train_size: \n",
    "        * float => proportion of data      \n",
    "        * int => absolute number of observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train, d_test = train_test_split(dataset, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train.shape, d_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "* we shall perform a **hedonic regression** using the homes dataset after cleaning.\n",
    "\n",
    "* for this we do not require the `date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "d_train = d_train.drop(['date'], axis = 1)\n",
    "d_test = d_test.drop(['date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "statsmodels requires that the function call be passed in be a string in the format `output ~ input_! + input_2 + ... input_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "function_call = 'price ~ ' + ' + '.join(d_train.columns[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod = smf.ols(function_call , data = d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = lmod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print('F statistic:   ',results.fvalue)\n",
    "print('F stat pvalue: ',results.f_pvalue)\n",
    "print('r squared:     ',results.rsquared)\n",
    "print('r squared adj: ',results.rsquared_adj)\n",
    "print('residuals df:  ',results.df_resid)\n",
    "print('SST:           ',results.mse_total*(results.df_resid + results.df_model))\n",
    "print('SSE:           ',results.mse_resid*results.df_resid)\n",
    "print('SSM:           ',results.mse_model*results.df_model)\n",
    "print('resid std err: ',results.mse_resid**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.arange(d_train.shape[0]),results.resid, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results.fittedvalues, results.resid, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 1.4 model Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_pred = results.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mse_prediction = 1/(d_test.shape[0])*np.sum((lmod_pred - d_test.price)**2)\n",
    "mse_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<span style='color:blue'>what do you think about the value of MSE ?</span>\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "we can also calculate the `mean_squared_error` using the method with the same name from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = d_test.price, y_pred = lmod_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.kstest(results.resid, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(results.resid, bins = 100, fit = scipy.stats.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot(results.resid, dist = scipy.stats.norm ,fit = True, line='45')\n",
    "plt.axis([-5,5,-15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>can we do anything to make the residuals Gaussian ?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_1 = smf.ols(function_call_1, data = d_train)\n",
    "\n",
    "results_1 = lmod_1.fit()\n",
    "print(results_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print('F statistic:   ',results_1.fvalue)\n",
    "print('F stat pvalue: ',results_1.f_pvalue)\n",
    "print('r squared:     ',results_1.rsquared)\n",
    "print('r squared adj: ',results_1.rsquared_adj)\n",
    "print('residuals df:  ',results_1.df_resid)\n",
    "print('SST:           ',results_1.mse_total*(results.df_resid + results.df_model))\n",
    "print('SSE:           ',results_1.mse_resid*results.df_resid)\n",
    "print('SSM:           ',results_1.mse_model*results.df_model)\n",
    "print('resid std err: ',results_1.mse_resid**.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "`F statistic:    1151.65066416\n",
    "F stat pvalue:  0.0\n",
    "r squared:      0.651343773911\n",
    "r squared adj:  0.650778199823\n",
    "residuals df:   17261.0\n",
    "SST:            4789.71978586\n",
    "SSE:            1669.96562456\n",
    "SSM:            3119.7541613\n",
    "resid std err:  0.311043256005`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "<span style='color:blue'>first plot `results.resid` followed by `results_1.resid` vs `results_1.fittedvalues` (similar to the previous plots)      \n",
    "what do you think about the residuals? </spab>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different plotting package\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "plot results.resid for a quick comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(d_train.shape[0]), results.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(d_train.shape[0]), results_1.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 700, plot_height = 400)\n",
    "p.scatter(results_1.fittedvalues, results_1.resid, color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod_pred_1 = results_1.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mse_prediction = 1/(d_test.shape[0])*np.sum((lmod_pred_1 - np.log(d_test.price))**2)\n",
    "mse_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mse_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.kstest(results_1.resid, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(results_1.resid, bins = 100, fit = scipy.stats.norm, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig = sm.qqplot(results_1.resid, dist = scipy.stats.norm ,fit = True, line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* can we infer anything from the Jarque-Bera test of normality ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.jarque_bera(results_1.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* the Jarque-Bera test is a test for normality that is based on sample skewness and kurtosis with     \n",
    "`H0: the distribution is normal`       \n",
    "`H1: the distribution is not normal`.   \n",
    "\n",
    "\n",
    "\n",
    "* the calculated statistic $JB = \\frac{N}{6} \\bigg(S^2 + \\frac{(K-3)^2}{4} \\bigg)$   \n",
    "* with a sample size > 2000 the test statistic is compared to a $\\chi^2$ distribution with 2 degrees of freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# this is what a chi-square distribution with df=2 looks like\n",
    "np.random.seed(40)\n",
    "chisq_sim = np.random.chisquare(2, 20000)\n",
    "sns.distplot(chisq_sim, bins = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* despite the fact that the Jarque-Bera test is conclusive, and there is enough evidence to reject the null, the JB statistic went from 266387.882 to 121.22. However for a p-value to not reject the Null the JB statistic needs to approximately between 0 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "# 2 OLS Regression using `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* scikit learn does not ingest categorical variables passed into the method input. instead all categorical variable need to be processed prior to running the model estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset.dtypes, dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 2.1 encoding categorical variables\n",
    "\n",
    "* `scikit-learn` does not automatically handle categorical variables.   \n",
    "* in order to use the `LinearRegression` module and other modules we have to encode all the categorical variable in dummy coding.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LabelEncoder` is the method that converts categorical non-numeric variables into numeric representation   \n",
    "`OneHotEncoder` is the method that converts numeric variables into dummy variable  \n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.unique(dataset.iloc[:,i], return_counts = True) for i in range(10,14)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have two catagorical variables starting at level `0` and two starting at level `1`\n",
    "\n",
    "hence these two variables require the use of `LabelEncoder` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "the following series of steps are often analogous for different methods of scikit-learn\n",
    "\n",
    "1- assign the method to a name space (creating an instance of that method)     \n",
    "**set the paramteres and arguments of the new instance method in this step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc = LabelEncoder()\n",
    "\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- apply the instance method `.fit` to ingest the data using the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.fit(dataset.condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - apply the instance method `.transform` to interpret the results and produce an output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.transform(dataset.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "steps 3 and 4 can often be combined together in a single expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_condition = lbc.fit(dataset.condition).transform(dataset.condition).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(lbc_condition, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc_grade = lbc.fit(dataset.grade).transform(dataset.grade).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_array = np.hstack([np.array(dataset.waterfront).reshape((-1,1)), \n",
    "                        np.array(dataset.view).reshape((-1,1)), \n",
    "                        lbc_condition, lbc_grade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_obj = enc.fit(categorical_array)\n",
    "\n",
    "cat_vars = fit_obj.transform(categorical_array).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "this is good.    \n",
    "\n",
    "however for the regression problem we the first dummy variable from every category to be removed in order to allow for correct calculation of an intercept \n",
    "\n",
    "how can we go about it ?\n",
    "\n",
    "display the instance methods and attributed of the `fit_obj` calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(fit_obj) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_obj.feature_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these indeces represent the first or every group of dummy variables corresponding to the 4 variables.      \n",
    "the last index is the total number of columns overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['view_'+str(i) for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ = ['waterfront1']+\\\n",
    "         ['view_'+str(i) for i in range(1,5)]+\\\n",
    "         ['con_'+str(i) for i in range(2,6)]+\\\n",
    "         ['g_'+str(i) for i in range(3,14)]\n",
    "names_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_clean = pd.DataFrame(np.delete(cat_vars, fit_obj.feature_indices_[:-1], 1), columns = names_)\n",
    "cat_var_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* drop the original categorical variables to substitute with the dummy data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset_skl = dataset.drop(['date'], axis = 1).reset_index(drop = True).copy()\n",
    "\n",
    "#both tables need to have the same index. \n",
    "#either drop index of dataset or assign its index value to vat_var_clean\n",
    "\n",
    "dataset_skl = dataset_skl.drop(['waterfront', 'view', 'grade', 'condition'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dataset_skl = pd.concat([dataset_skl, cat_var_clean], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_skl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "## 2.2 Model estimation and diagnistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# use the same seed to retrieve an indentical train/test split.\n",
    "d_train_skl, d_test_skl = train_test_split(dataset_skl, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model` takes an argument for the input and an argument for the output(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_x = d_train_skl.iloc[:,1:]\n",
    "train_y = np.log(d_train_skl.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "recall the steps from earlier: \n",
    "\n",
    "1- create an instance of the method and set the parameters and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression(fit_intercept = True, normalize = False, copy_X = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- apply the instsance method `.fit` using the variables or input and outpute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_fit = ols.fit(X = train_x, y = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results_1.params[0], ols.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "we can compare the coefficients from statsmodels `results` object and sklearn coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(results_1.params, columns = ['statsmodels']).sort_values(by = 'statsmodels').drop(['Intercept'], axis = 0)\n",
    "b = pd.DataFrame(ols_fit.coef_, columns = ['sklearn']).sort_values(by = 'sklearn').set_index(a.index)\n",
    "df = pd.concat([b,a], axis = 1).sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "* in order to obtain the fittedvalues and residuals we have to calculate these manually. \n",
    "\n",
    "$$\\begin{bmatrix} fitted\\ val1 \\\\ fitted\\ val2 \\\\ . \\\\ . \\\\ . \\\\ fitted\\ valN \\end{bmatrix} = intercept + \n",
    "\\begin{bmatrix} x_{1,1} & x_{1,2} & . . . & x_{1,m-1} & x_{1,m} \\\\ \n",
    "                x_{2,1} & \\ddots & . . . & x_{2,m-1} & x_{2,m} \\\\ \n",
    "                . & . & \\ddots & . & . \\\\ \n",
    "                . & . & . & \\ddots  & . \\\\ \n",
    "                x_{n-1,1} & x_{n-1,2} & . . . & x_{n-1,m-1} & x_{n-1,m} \\\\\n",
    "                x_{n,1} & x_{n,2} & . . . & x_{n,m-1} & x_{n,m} \n",
    "                \\end{bmatrix} \\times \\begin{bmatrix} \\theta_{bathrooms} \\\\ \\theta_{bedrooms} \\\\ . \\\\ \\theta_{grade[T.3]} \\\\ . \\\\ \\theta_{yr\\ renovated} \\end{bmatrix}$$\n",
    "                \n",
    "&nbsp;                \n",
    "\n",
    "$$Residuals = Output - Fitted\\ Values$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_fittedvalues = np.dot(train_x, np.array(ols.coef_).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_resids = train_y.values - ols_fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(train_x.shape[0]), ols_fittedvalues, color = 'peachpuff')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(ols_fittedvalues, ols_resids, color = 'peachpuff')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* the instance method `.score` of the fit object `ols` returns the coefficient of determination $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_rsq = ols.score(X = train_x, y = train_y)\n",
    "ols_rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly `fit.rank_` returns the degrees of freedom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deg_freedom = ols_fit.rank_\n",
    "deg_freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; \n",
    "\n",
    "$adj\\_r.squared$ can be calculated manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "n, k = train_x.shape[0], len(train_x.columns.values)\n",
    "n , k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "$adj\\_r.squared = 1 - \\bigg[\\frac{(1 - R^2)(n-1}{n-k-1}\\bigg] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_adj_rsq = 1 - ((1 - ols_rsq)*(n-1)/(n-k-1))\n",
    "ols_adj_rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "## 2.3 Model validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "test_x = d_test_skl.iloc[:,1:]\n",
    "test_y = np.log(d_test_skl.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "3- instead of `.transform()` the method `.predict()` takes the inputs of the test set and calculates a predicted output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ols_pred = ols_fit.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = test_y, y_pred = ols_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Addendum\n",
    "\n",
    "instead of using `OneHotEncoder()` the method `pandas.get_dummies()` allows us to convert a categorical variable into dummy variables and allows us to drop the first column by setting an argument within the method call.     \n",
    " \n",
    " \n",
    "since this is a pandas method it preserves the index of the original dataframe   \n",
    "\n",
    "using <U>dataset</U>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_waterfront = pd.get_dummies(dataset.waterfront, drop_first = True)\n",
    "pd_view = pd.get_dummies(dataset.view, drop_first = True)\n",
    "pd_condition = pd.get_dummies(dataset.condition, drop_first = True)\n",
    "pd_grade = pd.get_dummies(dataset.grade, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d = pd.concat([dataset.iloc[:,1:10], pd_waterfront, pd_view, pd_condition, pd_grade], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d.columns = dataset.columns[1:10].tolist() + names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d.head()"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
