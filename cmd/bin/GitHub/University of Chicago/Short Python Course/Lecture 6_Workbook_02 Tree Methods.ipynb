{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "## Non-parametric models\n",
    "\n",
    "### Tree methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "Preprocessing steps of the dataset from file `homes.csv`     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/homes.csv'\n",
    "dataset = pd.read_csv(filepath, header = 0, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['id','date', 'sqft_living15', 'lat', 'long', 'sqft_lot15', 'zipcode'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.yr_built = [2015 - yr for yr in dataset.yr_built]\n",
    "dataset.yr_renovated = [2015 - yr if yr != 0 else yr for yr in dataset.yr_renovated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = dataset.columns[0:6].tolist() + dataset.columns[-4:].tolist() + dataset.columns[6:10].tolist()\n",
    "dataset = dataset[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "we know from workshop_1 that the variables `condition` and `grade` start at level `1`. \n",
    "\n",
    "in order to avoid the additional step of `LabelEncoder()` we can simply subtract 1 from every element of the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.condition = [i-1 for i in dataset.condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.grade = [i-1 for i in dataset.grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.waterfront = dataset.waterfront.astype('category')\n",
    "dataset.view = dataset.view.astype('category')\n",
    "dataset.grade = dataset.grade.astype('category')\n",
    "dataset.condition = dataset.condition.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:,1:], dataset.iloc[:,0], test_size = .2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(categorical_features = [9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = enc.fit(dataset).transform(dataset).toarray()\n",
    "dataset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "# Tree Regression  \n",
    "\n",
    "<a href = 'http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html'>link</a>\n",
    "\n",
    "`DecisionTreeRegressor(criterion='mse', \n",
    "                        max_depth=None, \n",
    "                        min_samples_split=2, \n",
    "                        min_samples_leaf=1, \n",
    "                        max_features=None, \n",
    "                        random_state=None, \n",
    "                        min_impurity_decrease=0.0)`\n",
    "                        \n",
    "                        \n",
    "`criterion`: `mse` or `mae`      \n",
    "`max_depth`: the maximum depth of a tree. if not specified more nodes will be added until the leaves are pure      \n",
    "`min_samples_split`: the miniumum number of samples required to split a node     \n",
    "`min_sample_leaf`: the minimum number of samples required to become a leaf node    \n",
    "`max_features`: the number of features to consider when looking for the best split    \n",
    "`random_state`: seed      \n",
    "`min_impurity_decrease`: a node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(criterion = 'mse',\n",
    "                             splitter = 'best',\n",
    "                             max_depth = 10,\n",
    "                             min_samples_split = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X = x_train, y  = np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_tree = tree.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(x_train.shape[0]), np.log(y_train - y_train_pred_tree), color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 700, plot_height = 400)\n",
    "p.scatter(np.log(y_train_pred_tree), np.log(y_train - y_train_pred_tree), color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tree = pd.DataFrame(tree.feature_importances_, dataset.columns[1:], columns = ['value']).sort_values(by = ['value'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,8))\n",
    "plt.barh(width = df_tree.value, y = df_tree.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = np.log(y_test), y_pred = y_pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Random Forest Regression\n",
    "\n",
    "`RandomForestRegressor(n_estimators=10, \n",
    "                        criterion='mse', \n",
    "                        max_depth=None, \n",
    "                        min_samples_split=2, \n",
    "                        min_samples_leaf=1, \n",
    "                        max_features='auto', \n",
    "                        max_leaf_nodes=None, \n",
    "                        min_impurity_decrease=0.0, \n",
    "                        min_impurity_split=None, \n",
    "                        bootstrap=True, \n",
    "                        n_jobs=1, \n",
    "                        random_state=None, \n",
    "                        verbose=0)`\n",
    "                        \n",
    "`n_estimators=10`: number of trees in the forest    \n",
    "`criterion`: `mse` or `mae`      \n",
    "`max_depth`: the maximum depth of a tree. if not specified more nodes will be added until the leaves are pure      \n",
    "`min_samples_split`: the miniumum number of samples required to split a node     \n",
    "`min_sample_leaf`: the minimum number of samples required to become a leaf node    \n",
    "`max_features`: the number of features to consider when looking for the best split    \n",
    "`random_state`: seed      \n",
    "`min_impurity_decrease`: a node will be split if this split induces a decrease of the impurity greater than or equal to this value      \n",
    "`n_jobs`: the number of jobs to run in parallel for both fit and predict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 150,\n",
    "                        criterion='mse',\n",
    "                        max_depth = 6,\n",
    "                        min_samples_split =20,\n",
    "                        bootstrap = True,\n",
    "                        n_jobs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X = x_train, y = np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.DataFrame(rf.feature_importances_, dataset.columns[1:], columns = ['value']).sort_values(by = ['value'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,8))\n",
    "plt.barh(width = df_rf.value, y = df_rf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf = rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 800, plot_height = 400)\n",
    "p.scatter(range(x_train.shape[0]), np.log(y_train - y_train_pred_rf), color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width = 700, plot_height = 400)\n",
    "p.scatter(np.log(y_train_pred_tree), np.log(y_train - y_train_pred_rf), color = 'purple')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true = np.log(y_test), y_pred = y_pred_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
