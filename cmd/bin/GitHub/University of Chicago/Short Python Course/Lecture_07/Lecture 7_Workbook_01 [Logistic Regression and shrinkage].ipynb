{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Supervised Learning\n",
    "\n",
    "## Parametric models\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Logistic Regression with `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<a href='http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data'>dataset</a>\n",
    "\n",
    "\n",
    "<a href='http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names'>dataset description</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 data cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred = pd.read_csv('data/credit approval.csv', names = ['sex','age','debt','married','bank_customer','edu','ethnicity',\n",
    "                                                       'yrs_employed', 'prior_default','employed','cscore','driver_lic',\n",
    "                                                       'citizen','zipcode','income','approval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred = cred.dropna().reset_index(drop = True)\n",
    "cred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every variable in this dataset is encoded to hide the actual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = cred.drop(['sex','married', 'bank_customer', 'edu', 'ethnicity','driver_lic','citizen','zipcode'], axis = 1)\n",
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.replace(to_replace = {'prior_default':{'t':0, 'f':1},\n",
    "                           'employed':{'t':1, 'f':0},\n",
    "                           'approval':{'-':0,'+':1}},\n",
    "                             inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.prior_default = cred.prior_default.astype('category')\n",
    "cred.employed = cred.employed.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp; \n",
    "\n",
    "* **unalikability** is a measure of variability in a categorical variable.  \n",
    "* based on the following <a href = 'http://ww2.amstat.org/publications/jse/v15n2/kader.html'>publication</a> (sec 2.5) a coefficient of variability for a categorical variable can be calculated as \n",
    "\n",
    "$$u = 1 - \\Sigma_i\\ p_i^2 $$\n",
    "\n",
    "with $p_i=\\frac{k_i}{n}$ where $k_i$ is the count of observations for a single category and $n$ is the total number of observations for that variable.\n",
    "\n",
    "* variables with low coefficient do not have a lot of variability in the data and can be ignored or dropped form the table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def unalike(c_var):\n",
    "    c_var = np.unique(np.array(c_var), return_counts = True)[1]\n",
    "    obs_num = sum(c_var)\n",
    "    return(1 - sum([(i/obs_num)**2 for i in c_var]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "un = pd.Series(list(map(unalike, (cred.prior_default, cred.employed,))), name = 'coef')\n",
    "\n",
    "nm = pd.Series(['prior_default', 'employed'], name = 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pd.concat([nm, un], axis = 1).sort_values(by = 'coef', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* normalize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "age_norm = scale(cred.age, with_mean = False)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(12, 5)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.distplot(cred.age, ax = ax[0])\n",
    "sns.distplot(age_norm, ax = ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.replace({'debt': {0: 10**-16},\n",
    "              'yrs_employed':{0:10**-16},\n",
    "              'cscore':{0:10**-16},\n",
    "              'income':{0:10**-16}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debt_log = np.log(cred.debt)\n",
    "debt_norm = scale(debt_log, with_mean = False)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(12, 5)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.distplot(cred.debt, ax = ax[0])\n",
    "sns.distplot(debt_log, ax = ax[1])\n",
    "sns.distplot(debt_norm, ax = ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "yrs_employed_log = np.log(cred.yrs_employed)\n",
    "yrs_employed_norm = scale(yrs_employed_log, with_mean = False)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(12, 5)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.distplot(cred.yrs_employed, ax = ax[0])\n",
    "sns.distplot(yrs_employed_log, ax = ax[1])\n",
    "sns.distplot(yrs_employed_norm, ax = ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cscore_log = np.log(cred.cscore)\n",
    "cscore_norm = scale(cscore_log, with_mean = False)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(12, 5)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.distplot(cred.cscore, ax = ax[0])\n",
    "sns.distplot(cscore_log, ax = ax[1])\n",
    "sns.distplot(cscore_norm, ax = ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "income_log = np.log(cred.income)\n",
    "income_norm = scale(income_log, with_mean = False)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(12, 5)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.distplot(cred.income, ax = ax[0])\n",
    "sns.distplot(income_log, ax = ax[1])\n",
    "sns.distplot(income_norm , ax = ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.age = age_norm\n",
    "cred.debt = debt_norm\n",
    "cred.yrs_employed = yrs_employed_norm\n",
    "cred.cscore = cscore_norm\n",
    "cred.income = income_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.unique(cred.approval, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset after cleaning\n",
    "cred.to_csv('data/cred_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, confusion_matrix, log_loss, roc_curve\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 5.2 model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred_train, cred_test = train_test_split(cred, test_size = 0.2, random_state = 65) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cred_train = cred_train.reset_index(drop = True)\n",
    "cred_test = cred_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "function_call = 'approval ~ ' + ' + '.join(cred_train.columns[:-1])\n",
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "binom_fit = smf.glm(function_call,family = sm.families.Binomial(),data = cred_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results = binom_fit.summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%load udf/signif.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "signif(results.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom_fit = smf.glm('approval ~ prior_default + yrs_employed + cscore',family = sm.families.Binomial(),data = cred_train).fit()\n",
    "results_1 = binom_fit.summary()\n",
    "signif(results_1.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 5.3 model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Null deviance: {} on {} degrees of freedom'.format(binom_fit.null_deviance, binom_fit.df_model+binom_fit.df_resid))\n",
    "print('Residual deviance: {} on {} degrees of freedom'.format(binom_fit.deviance, binom_fit.df_resid))\n",
    "print('aic: ',binom_fit.aic)\n",
    "print('log lik: ',binom_fit.llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "predicted_prob = binom_fit.predict(cred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "predicted_thresh = [0 if i < 0.5 else 1 for i in predicted_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_true = cred_test.approval.astype(np.int64), y_pred = predicted_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true = cred_test.approval, y_score = predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = auc(x = fpr, y = tpr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(fpr,tpr,label='AUC = {}'.format(AUC), color = 'orange')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "log_loss(y_true = cred_test.approval, y_pred = predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "is this a good or a bad logloss ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.linspace(.0001,.9999999,1000)\n",
    "log_prob = -np.log(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "plt.plot(prob, log_prob,'-')\n",
    "plt.plot(prob, [log_loss(y_true = cred_test.approval, y_pred = predicted_prob) for i in range(1000)], '--', color = 'coral')\n",
    "plt.legend(['log_loss','logistic regression'], handlelength = 5, prop = {'size': 15} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "# 6 Logistic Regression with `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_categ = cred.loc[:,['prior_default', 'employed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(categorical_features = [3,4])\n",
    "enc.fit(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.feature_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_dummy = pd.DataFrame(enc.transform(cred).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "drop one (the first) dummy column for every variable according to the `feature_indides_` obtained from the `enc.fit` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_dummy.drop(enc.feature_indices_[:-1], axis = 1, inplace = True)\n",
    "cred_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_dummy.columns = ['pdT','empT'] + cred.columns[0:3].tolist() + cred.columns[5:].tolist() \n",
    "cred_dummy.approval = cred_dummy.approval.astype(np.int64)\n",
    "cred_dummy.pdT = cred_dummy.pdT.astype(np.int64)\n",
    "cred_dummy.empT = cred_dummy.empT.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cred_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_dummy.to_csv('data/cred_ohe.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 6.2 model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cred_dummy.iloc[:,:-1], cred_dummy.iloc[:,-1], \n",
    "                                                    test_size = 0.2, random_state = 65) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(fit_intercept = True)\n",
    "log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a reminder we can comapre to the `results.tables` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif(results.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `scikit-learn` does not return any model diagnostics that will help us assess the importance of variables.    \n",
    "* one way around this is to build different models using combinations of independent variables and compare the confusion matrix and ROC curve for each one.   \n",
    "* another way to assess variable importance is by using lasso regression.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 6.3 lasso and ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 20\n",
    "alphas = np.logspace(-5, 5, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "for c in alphas:\n",
    "    clf = LogisticRegression(C = c, penalty = 'l2' )\n",
    "    clf.fit(x_train, y_train)\n",
    "    coefs.append(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize = (15,10)).gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.legend(cred_dummy.columns, loc = 'best', handlelength = 5, prop={'size': 15})\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif(results_1.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_mod = pd.concat([cred_dummy.loc[:,['pdT', 'empT']], cred.loc[:,['cscore','approval']]], axis = 1)\n",
    "\n",
    "cred_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cred_mod.iloc[:,:-1], cred_mod.iloc[:,-1], \n",
    "                                                    test_size = 0.2, random_state = 65) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(fit_intercept = True)\n",
    "log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(x_test)\n",
    "y_prob = log_reg.predict_proba(x_test)\n",
    "y_probone = list(map(lambda x: x[1], y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_true = y_test, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_probone)\n",
    "AUC = auc(x = fpr, y = tpr )\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(fpr,tpr,label='AUC = {}'.format(AUC), color = 'orange')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_true = y_test, y_pred = y_probone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
