{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# 1 k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* k-means clusting is an unsupervised learning technique used to partition observations in a dataset into k-clusters in which observations in each cluster belong to a center point (the centroid).    \n",
    "* the algorithm starts by assigning k number of centroids to random locations in m-dimensional space (m: number of columns or features in the dataset).   \n",
    " - 1 each sample in the dataset gets assigned to the nearest centroid based (most commonly) on the squared Euclidean distance.  \n",
    " - 2 the centroids for each cluster gets recomputed by taking the mean of all the samples (the center of the samples in m-dimentional space) that belong to that cluster.   \n",
    "* iterative refinement of steps 1 and 2 continues until the stopping criterina is met: centroids do not move significantly and the sum of Euclidean distances is minimized.  \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "## 1.1 **Example 1** \n",
    "\n",
    "we look at a dataset where we have 3 distinctly defined groups.      \n",
    "\n",
    "From the UCI Machine Learning Repository the <a href='https://archive.ics.uci.edu/ml/datasets/seeds'>seeds</a> dataset examines and classifies kernals into 3 groups based on 7 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# modify the column names for viewing convenience\n",
    "col_names = ['area', 'perimeter', 'compactness', 'length of kernel', 'width of kernel', 'asymmetry coefficient',\n",
    "             'length of kernel groove', 'variety' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "seeds = pd.read_table('data/seeds_.txt', header = -1, index_col = False, sep = '\\s+' , names = col_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "seeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "seeds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "column `variety` is the actual kernel assignment.     \n",
    "\n",
    "\n",
    "isolate this column and drop it form <U>seeds</U>, we shall use it later to assess the performance of the clustering algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "seed_class = seeds.variety.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "change levels to make between 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "seed_class = seed_class - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts is a pandas method similar to Table in R\n",
    "\n",
    "\n",
    "seed_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# drop variety column from seeds\n",
    "seeds.drop(['variety'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* the reason variety column is `y_of_train` and `y_of_test` (vs y_train and y_test) is because there is no training component here. We will only use the y subsets to compare the resulting groups.   \n",
    "\n",
    "* this is an example that happens to come with training wheels.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_of_train, y_of_test = train_test_split(seeds, seed_class, test_size = .2, random_state = 33 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "`sklearn.cluster.KMeans(n_clusters=8, \n",
    "                        init='k-means++', \n",
    "                        n_init=10, \n",
    "                        max_iter=300,   \n",
    "                        verbose=0, \n",
    "                        copy_x=True, n_jobs=1, \n",
    "                        algorithm='auto')`\n",
    "                        \n",
    "* assigning the parameter `n_clusters` is an arbitrary choise and there's a couple of ways that we can assess which `n_clusters` returns the best separation between clusters.  \n",
    "\n",
    "* `init = 'k-means++'`  selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. other options: `'random'` or `ndarray` of starting points.\n",
    "\n",
    "* `n_init` number of times the algorithm runs with different centroids.    \n",
    "* `max_iter` max number of iterations between steps (1) and (2) mentioned earlier above to refine the centroid locations.  \n",
    "* `copy_x = {True, False}` default `True`, original dataset is kept intact. `False` the data sample is centered.    \n",
    "\n",
    "\n",
    "the resulting `KMeans` object returns a number of attributes, most importantly: \n",
    "\n",
    "`.culster_centers_` is an array of shape (m, k) where m is the number of attributes (columns) in the dataset and k is the number of clusters.   \n",
    "`labels_` an arrary of integers from 0 to k-1 that assigns each datapoint to a cluster.   \n",
    "`inertia_` sum of squared distances of samples to their closest cluster center.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<a id = 'loc_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**VAF**    \n",
    " - `VAF` **Variance Accounted For** is one of the metric used to assess whether the number of clusters selected is optimal.  \n",
    " - `VAF` is the ratio between the within-clusters sum of squares and the total sum of squres.    \n",
    " - `VAF` values for different `n_cluster` are calculated and the resulting values are used to generate a **scree plot**    \n",
    "\n",
    "\n",
    "**silhouette_score**    \n",
    " - the `silhouett_score` `[1,-1]` from `sklearn.metrics` computes a silhouette coefficient for every `n_cluster` assignment using the original dataset and the resulting `labels_` attribute.    \n",
    " - best value is 1 and worst is -1. Values near 0 indicates overlapping clusters. negative values indicate that samples have been assigned to the wrong cluster. increasiing positive values indicate better cluster quality and better separation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "run `%load udf/VAF.py` method [here](#VAF)\n",
    "<a href = '#VAF'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "silh = []\n",
    "vaf = []\n",
    "\n",
    "for k_clusters in range(2,15):\n",
    "    kmc = KMeans(n_clusters = k_clusters)\n",
    "    kmc.fit(x_train)\n",
    "    inertia.append(kmc.inertia_)\n",
    "    silh_ = silhouette_score(x_train, kmc.labels_, metric = 'euclidean')\n",
    "    silh.append(silh_)\n",
    "    # vaf is the third object in the array returned by VAF()\n",
    "    vaf_ = VAF(x_train, kmc)[3]\n",
    "    vaf.append(vaf_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n",
    "\n",
    "ax1.plot(range(2,15), vaf )\n",
    "ax1.plot(range(2,15), vaf, 'o')\n",
    "ax1.set_title('scree plot')\n",
    "ax1.set_xlabel('clusters')\n",
    "ax1.set_ylabel('VAF')\n",
    "\n",
    "ax2.plot(range(2,15), silh)\n",
    "ax2.plot(range(2,15), silh, 'o')\n",
    "ax2.set_title('silhouette coefs')\n",
    "ax2.set_xlabel('clusters')\n",
    "ax2.set_ylabel('coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is clear that the `VAF` is not returning the optimal number of clusters which we know to be 3 from the original dataset  \n",
    "\n",
    "let us select number of clusters 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "kmc_4 = KMeans(n_clusters = 4).fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "* refit the model with the number of clusters chosen based on the *scree plot* and the *silh coefficients*.   \n",
    "* predict the test sample.  \n",
    "\n",
    "\n",
    "* there is no explicit methodology to carry out model validation for clustering since this is an unsupervised learning method. the only way to test the validity of the model is to classify the test set according to the trained model and compare the proportions of observations in every cluster.     \n",
    "\n",
    "\n",
    "1- calculate the proportion of observartions in each of the clusters in the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.unique(kmc_4.labels_, return_counts = True)[1]/x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "2- fit the model to the test set and cluster the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pred_variety = kmc_4.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "3- calculate the proportions of observations in the test cluster and compare to the train cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.unique(pred_variety, return_counts = True)[1]/x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "`TSNE` or **t-distribution Stochastic Neighbor Embegging** is a visualization tool from `sklearn.manifold` that converts similarities between datapoints into join probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.    \n",
    "\n",
    "PCA is recommended before using `TSNE` especially with higher number of dimentions (>50).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "`class sklearn.manifold.TSNE(n_components=2,             \n",
    "                             learning_rate=200.0,       \n",
    "                             n_iter=1000,               \n",
    "                             n_iter_without_progress=300,\n",
    "                             metric = 'euclidean',       \n",
    "                             verbose=0,                 \n",
    "                             random_state=None) `       \n",
    "                        \n",
    "`learning_rate` between [10.0 1000.0]. If the learning rate is too high the data may look like a ball, if the learning rate is too low the data may look compressed in a dense cloud.                          \n",
    "\n",
    "`n_iter` maximum number of iterations for the optimization    \n",
    "`n_iter_without_progress`  number of iterations without progress before the optimization is aborted    \n",
    "`metric` euclidian by default    \n",
    "`random state` the seed used by the random number generator. controls the random initialization    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2)\n",
    "tsne_fit = tsne.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "clust = zip(tsne_fit[:,0], tsne_fit[:,1], kmc_4.labels_)\n",
    "\n",
    "# if you list clust it looks like this \n",
    "#[(3.490185, -4.8993158, 3),\n",
    "# (-7.8433094, 10.558871, 1),\n",
    "# (-9.051569, 8.7391624, 1),\n",
    "# (6.6155434, -11.603072, 0),\n",
    "\n",
    "for x, y, label in clust:\n",
    "    plt.plot(x, y, 'o', color = plt.cm.tab10(label/10.))\n",
    "\n",
    "plt.title('k = 4 clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "the seeds in the original dataset are categorized into 3 categories   \n",
    "we can check to see if the features of the seeds contain enough information to distinguish the seeds   \n",
    "since we do not need to compare sample proportions between train and test we will use the entire <U>seeds</U> set and `seed_class`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "kmc_3 = KMeans(n_clusters = 3).fit(seeds)\n",
    "tsne_full = TSNE(n_components = 2)\n",
    "tsne_full_fit = tsne_full.fit_transform(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "clust_1 = zip(tsne_full_fit[:,0], tsne_full_fit[:,1], kmc_3.labels_)\n",
    "for x, y, label in clust_1:\n",
    "    ax1.plot(x, y, 'o', color = plt.cm.tab10(label/10.))\n",
    "ax1.set_title('k = 3 clusters')\n",
    "ax1.set_xlabel('component 1')\n",
    "ax1.set_ylabel('component 2')\n",
    "    \n",
    "clust_2 = zip(tsne_full_fit[:,0], tsne_full_fit[:,1], seed_class)\n",
    "for x, y, label in clust_2:\n",
    "    ax2.plot(x, y, 'o', color = plt.cm.tab10(label/10.))\n",
    "ax2.set_title('actual seed varieties')\n",
    "ax2.set_xlabel('component 1')\n",
    "ax2.set_ylabel('component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: compare the groupings not the colors , the colors are assigned randomly   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "_______________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## 1.2 **Example 2**\n",
    "\n",
    "* the `flavors_cacao.csv` dataset contains the expert rating of over 1700 chocolate bars along with a plethora of information about the origins of these comestible delights.   \n",
    "\n",
    "* more information about the dataset can be found <a href = 'https://www.kaggle.com/rtatman/chocolate-bar-ratings'>here</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "flavors = pd.read_csv('data/flavors_cacao.csv', header = 0)\n",
    "flavors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flavors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "there's a small problem      \n",
    "missing values in the dataset are coded as empty spaces of length 1. hence `pandas.read_txt()` is unable to identify them.   \n",
    "in order to overcome this problem use `DataFrame.replace()` with argument `regex = True` as follows:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "flavors.replace(to_replace={r'^\\s':np.nan}, regex = True, inplace = True)\n",
    "flavors.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* kmeans clustering can only be applied to **numeric** variables. categorical variables which are strings need to be converted to integers in order to compute. \n",
    "\n",
    "\n",
    "first we convert the categorical columns into datatype category using `.astype()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "flavors.company = flavors.company.astype('category')\n",
    "flavors.origin_name = flavors.origin_name.astype('category')\n",
    "flavors.company_loc = flavors.company_loc.astype('category')\n",
    "flavors.bean_type = flavors.bean_type.astype('category')\n",
    "flavors.broad_bean_origin = flavors.broad_bean_origin.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flavors.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<a id = 'loc_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "second we replace the categories (which are strings) with the actual integer labels for each categorry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "flavors.company = flavors.company.cat.codes\n",
    "flavors.origin_name = flavors.origin_name.cat.codes\n",
    "flavors.company_loc = flavors.company_loc.cat.codes\n",
    "flavors.bean_type = flavors.bean_type.cat.codes\n",
    "flavors.broad_bean_origin = flavors.broad_bean_origin.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "flavors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "coco_train, coco_test = train_test_split(flavors, test_size = .2, random_state = 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "run `%load data/VAF.py` method [here](#VAF)\n",
    "<a href = '#VAF'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "inertia_coco = []\n",
    "silh_coco = []\n",
    "vaf_coco = []\n",
    "\n",
    "for k_clusters in range(5,70,2):\n",
    "    kmc_coco = KMeans(n_clusters = k_clusters)\n",
    "    kmc_coco.fit(coco_train)\n",
    "    inertia_coco.append(kmc_coco.inertia_)\n",
    "    silh_ = silhouette_score(coco_train, kmc_coco.labels_, metric = 'euclidean')\n",
    "    silh_coco.append(silh_)\n",
    "    vaf_ = VAF(coco_train, kmc_coco)[3]\n",
    "    vaf_coco.append(vaf_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n",
    "\n",
    "ax1.plot(range(5,70,2), vaf_coco )\n",
    "ax1.plot(range(5,70,2), vaf_coco, 'o')\n",
    "ax1.set_title('scree plot')\n",
    "ax1.set_xlabel('clusters')\n",
    "ax1.set_ylabel('VAF')\n",
    "\n",
    "ax2.plot(range(5,70,2), silh_coco)\n",
    "ax2.plot(range(5,70,2), silh_coco, 'o')\n",
    "ax2.set_title('silhouette coefs')\n",
    "ax2.set_xlabel('clusters')\n",
    "ax2.set_ylabel('coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "kmc_pick = KMeans(n_clusters = 7, n_init = 10).fit(coco_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.unique(kmc_pick.labels_, return_counts = True)[1]/coco_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pred_variety = kmc_pick.predict(coco_test)\n",
    "np.unique(pred_variety, return_counts = True)[1]/coco_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "tsne_coco = TSNE(n_components = 2)\n",
    "tsne_coco_fit = tsne_coco.fit_transform(coco_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "clust_coco = zip(tsne_coco_fit[:,0], tsne_coco_fit[:,1], kmc_pick.labels_)\n",
    "\n",
    "for x, y, label in clust_coco:\n",
    "    plt.plot(x, y, 'o', color = plt.cm.tab20(label/10.))\n",
    "\n",
    "plt.title('k = 7 clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "___________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "# 2 Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "* we begin with a simple example to demonstrate how PCA works.   \n",
    "\n",
    "\n",
    "* principle component analysis projects the independent variables onto a new set of orthogonal axis that ensure maximization of the variance for each idependent variable along the new axis.  \n",
    "\n",
    "\n",
    "* PCA is an unsupervised learning technique that is primarily used for dimentionality reduction and it can improve the outcome of many supervised learning techniques when applied to the new coordinate system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/simple_pca_example.csv', header = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PCA(n_components=None, \n",
    "            copy=True, \n",
    "            svd_solver='auto', \n",
    "            iterated_power='auto', \n",
    "            random_state=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = None)\n",
    "\n",
    "testpca = pca.fit(data)\n",
    "transformed = pca.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "testpca.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "testpca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.bar(range(3), testpca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# this is manual calculation of what testpca.explaind_variance_ratio_ is\n",
    "\n",
    "testpca.explained_variance_ / np.sum(testpca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* the **eigen vectors** returned by `pca-object.components_` are unit vectors (magnitude = 1) that define the new model space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "columns_ , index_ = ['V1','V2','V3']  , ['Comp 1', 'Comp 2', 'Comp 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "eigenVec = pd.DataFrame(testpca.components_, columns = columns_, index = index_).transpose().copy()\n",
    "eigenVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.dot(eigenVec['Comp 1'], eigenVec['Comp 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.dot(eigenVec['Comp 1'], eigenVec['Comp 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "np.dot(eigenVec['Comp 2'], eigenVec['Comp 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "creating a new frame of reference to visualize the new components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x1 = np.arange(-50,200)*eigenVec['Comp 1'][0]\n",
    "y1 = np.arange(-50,200)*eigenVec['Comp 1'][1]\n",
    "z1 = np.arange(-50,200)*eigenVec['Comp 1'][2]\n",
    "\n",
    "\n",
    "x2 = np.arange(-50,200)*eigenVec['Comp 2'][0]\n",
    "y2 = np.arange(-50,200)*eigenVec['Comp 2'][1]\n",
    "z2 = np.arange(-50,200)*eigenVec['Comp 2'][2]\n",
    "\n",
    "x3 = np.arange(-50,200)*eigenVec['Comp 3'][0]\n",
    "y3 = np.arange(-50,200)*eigenVec['Comp 3'][1]\n",
    "z3 = np.arange(-50,200)*eigenVec['Comp 3'][2]\n",
    "\n",
    "line_1 = pd.concat([pd.Series(x1), pd.Series(y1), pd.Series(z1)], axis = 1)\n",
    "line_2 = pd.concat([pd.Series(x2), pd.Series(y2), pd.Series(z2)], axis = 1)\n",
    "line_3 = pd.concat([pd.Series(x3), pd.Series(y3), pd.Series(z3)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is required to plot a 3d view\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,7))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs = test.iloc[:,0], ys = test.iloc[:,1] , zs = test.iloc[:,2] )\n",
    "\n",
    "ax.plot(xs = line_1.iloc[:,0], ys = line_1.iloc[:,1] , zs = line_1.iloc[:,2], color = 'red')\n",
    "ax.plot(xs = line_2.iloc[:,0], ys = line_2.iloc[:,1] , zs = line_2.iloc[:,2], color = 'red')\n",
    "ax.plot(xs = line_3.iloc[:,0], ys = line_3.iloc[:,1] , zs = line_3.iloc[:,2], color = 'red')\n",
    "\n",
    "\n",
    "ax.mouse_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "* in order to obtain the new factors use the instance method `.fit_transform` on the `PCA` object using the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "Factors = pd.DataFrame(testpca.fit_transform(test))\n",
    "Factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "with a dependent variable we can use the new factors as independent variables to estimate a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "m490 = pd.read_csv('data/extended_pca_example.csv', header = 0)\n",
    "m490.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "m490.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "function_call = 'Y' + ' ~ ' + '+'.join(m490.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lmod = smf.ols(function_call , data = m490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = lmod.fit().summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'loc_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run `%load data/signif.py` method [here](#signif)\n",
    "<a href = '#signif'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signif(results.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "x_490 = m490.iloc[:,1:]\n",
    "y_490 = m490.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pca_490  = PCA(n_components = None).fit(x_490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca_490.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,7))\n",
    "#plt.xlim(1,20)\n",
    "plt.bar(range(491), pca_490.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "names = ['PC' + str(i) for i in range(1,492)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pca_factors = pd.DataFrame(pca_490.fit_transform(x_490), columns = names)\n",
    "pca_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "## Running R script within Python Kernel    \n",
    "&nbsp;\n",
    "\n",
    "* package `relaimpo` in **R** has no equivalent in **Python** \n",
    "* using package `rpy2` we can **R** code in jupyter notebook inside a **Python** kerel\n",
    "\n",
    "to begin, install the package `rpy2` in Anaconda comand prompt:\n",
    "\n",
    "### conda install rpy2\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R code begins\n",
    "\n",
    "#### relative importance of `output ~ PC_1 + PC_2 + . . . PC_490`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do this only once\n",
    "#%R install.packages(\"relaimpo\", repos = 'https://CRAN.R-project.org', quiet = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%R install.packages(\"caret\",  repos = 'https://CRAN.R-project.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R rm(list = ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "library(relaimpo)\n",
    "m490 = read.csv('data/extended_pca_example_r.csv', sep = ',')\n",
    "pca <- prcomp(m490[,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "df = data.frame(y = m490$Y, pca$x)\n",
    "model <- lm(y ~ . , df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "metric <- calc.relimp(model,  type = 'first')\n",
    "metric.first.rank<-metric@first.rank\n",
    "metric.first.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ranks = %R print(metric.first.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "rank_names = %R print(names(metric.first.rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R code ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(rank_names[70:80])\n",
    "print(ranks[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranked_factors = pd.DataFrame(rank_names, ranks).reset_index().sort_values(by = ['index'], axis = 0).iloc[:,1]\n",
    "ranked_factors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "rearrange the columns of `pca_factors` table using the new order obtained from relative importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pca_factors_ranked = pca_factors[ranked_factors]\n",
    "pca_factors_ranked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "this is the order of importance of the principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "we can rank the variables `X1` thru `X491` also using relative importance   \n",
    "\n",
    "in this process we are assessing PCA by relative importance,  we are only checking to see among the native variables what is the rank of their importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R code begins   \n",
    "\n",
    "#### relative importance of `output ~ x_1 + x_2 + . . . x_490`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "rm(list = ls())\n",
    "library(relaimpo)\n",
    "m490 = read.csv('data/extended_pca_example_r.csv', sep = ',')\n",
    "\n",
    "model_490 <- lm(Y ~ . , m490 )\n",
    "\n",
    "metric_490 <- calc.relimp(model_490,  type = 'first')\n",
    "metric_490.first.rank<-metric_490@first.rank\n",
    "metric_490.first.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_m490 = %R print(metric_490.first.rank)\n",
    "rank_m490_names = %R print(names(metric_490.first.rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R code ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(rank_m490_names[70:80])\n",
    "print(ranks_m490[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m490_ranked_variables = pd.DataFrame(rank_m490_names, ranks_m490).reset_index().sort_values(by = ['index'], axis = 0).iloc[:,1]\n",
    "m490_ranked_variables.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "m490_variables_ranked = m490.iloc[:,1:][m490_ranked_variables]\n",
    "m490_variables_ranked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "at this point we have developed two data frames and in total we can have four different dataframes   \n",
    "\n",
    "1- Native dataframe unchanged           \n",
    "2- dataframe with y: output, X: reordered according to relative importance       \n",
    "3- dataframe with y: output, X: PCA components              \n",
    "4- dataframe with y: output, X: PCA components reordered according to relative importance     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "### comparing $R^2$ of three different models \n",
    "\n",
    "\n",
    "* we would like to compare the incremental increase in $R^2$ between all three models:   \n",
    "    - the first model is the native model of `Y ~ X1, X2, ..... X491`\n",
    "    - the second model is native model with independent variables ordere according to relative importance measure `Y ~ X297, X345, ..... X242`\n",
    "    - the third model is the model where the variables are replaced with the ranked PCA factors `Y ~ PC79, PC176, ..... X475`\n",
    "    \n",
    "We loop thru the column adding one column at each iteration and calculating $R^2$, then we plot the values of $R^2$ from each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- native model\n",
    "\n",
    "we want to observe the improvement in $R^2$ as we add in variables sequentially to the model \n",
    "\n",
    "to do this we estimate a linear model about 300 times and each time we add a single variable and calculate and grab the value of $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_m490_rsq = []\n",
    "for i in range(2,300):\n",
    "    func_call = 'Y ~ ' + '+'.join(m490.columns.tolist()[1:i])\n",
    "    lmod_rsq = smf.ols(func_call, data = m490).fit().rsquared\n",
    "    model_m490_rsq.append(lmod_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- ranked variables of native model\n",
    "\n",
    "prepare the DataFrame of output `Y` and ranked order of independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranked_m490 = pd.concat([pd.Series(y_490).reset_index(drop=True), m490_variables_ranked], axis = 1)\n",
    "ranked_m490.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m490_ranked_rsq = []\n",
    "for i in range(2,300):\n",
    "    func_call = 'Y ~ ' + '+'.join(ranked_m490.columns.tolist()[1:i])\n",
    "    lmod_rsq = smf.ols(func_call, data = ranked_m490).fit().rsquared\n",
    "    model_m490_ranked_rsq.append(lmod_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### 3- PCA/PCR facrors without ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCR_df = pd.concat([pd.Series(y_490).reset_index(drop=True), pca_factors], axis = 1)\n",
    "PCR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PCR_rsq = []\n",
    "for i in range(2,300):\n",
    "    func_call = 'Y ~ ' + '+'.join(PCR_df.columns.tolist()[1:i])\n",
    "    lmod_rsq = smf.ols(func_call, data = PCR_df).fit().rsquared\n",
    "    model_PCR_rsq.append(lmod_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "### 4- ranked pca factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare the DataFrame of output `Y` and ranked PCA factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "PCR_df_ranked = pd.concat([pd.Series(y_490).reset_index(drop=True), pca_factors_ranked], axis = 1)\n",
    "PCR_df_ranked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model_PCR_ranked_rsq = []\n",
    "for i in range(2,300):\n",
    "    func_call = 'Y ~ ' + '+'.join(PCR_df_ranked.columns.tolist()[1:i])\n",
    "    lmod_rsq = smf.ols(func_call, data = PCR_df_ranked).fit().rsquared\n",
    "    model_PCR_ranked_rsq.append(lmod_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "plot the values of $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "plt.plot(range(298), model_m490_rsq, color = 'blue')\n",
    "plt.plot(range(298), model_m490_ranked_rsq, color = 'green')\n",
    "plt.plot(range(298), model_PCR_rsq, color = 'red')\n",
    "plt.plot(range(298), model_PCR_ranked_rsq, color = 'magenta')\n",
    "plt.axhline(.95, linewidth = 1, linestyle = '--', color = 'black')\n",
    "plt.legend(['native model','native model ranked','PCR','ranked PCR'],loc = 'best', prop = {'size':15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<a id = 'VAF'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%load udf/VAF.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "[back to seeds analysis](#loc_1)\n",
    "<a href = '#loc_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "[back to chocolate flavor analysis](#loc_2)\n",
    "<a href = '#loc_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'signif'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%load udf/signif.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "[back to PCA](#loc_3)\n",
    "<a href = '#loc_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
