{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "## Non-parametric models\n",
    "\n",
    "### CART  (Classification and Regression Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 classification trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import auc, confusion_matrix, log_loss, roc_curve\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conda install -c conda-forge python-graphviz**     \n",
    "**conda install -c conda-forge pydot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import pydot\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cred = pd.read_csv('data/cred_ohe.csv', header = 0)\n",
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cred.iloc[:,:-1], cred.iloc[:,-1], \n",
    "                                                    test_size = 0.2, random_state = 65) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionTreeClassifier(criterion ='gini',    \n",
    "                        splitter='best', \n",
    "                        max_depth=None,    \n",
    "                        min_samples_split=2,    \n",
    "                        min_samples_leaf=1,   \n",
    "                        max_features=None,    \n",
    "                        random_state=None,    \n",
    "                        max_leaf_nodes=None)`\n",
    "\n",
    "`criterion: {'gini', 'random'}` the method used to measure the quality of the split.     \n",
    "  - `gini` (default) [0,1] is a measure of the probability of being incorrect if you randomly assign labels to an element in the set if it was randomly labeled according to the distribution of labels in the subset.\n",
    "  \n",
    "\n",
    "`max_depth` the max depth of the tree.   \n",
    "`min_samples_split` the minimum samples requires to split a node. `int: number` or `float: percentage`  \n",
    "`min_samples_leaf` the minimum number of samples requires to be in a leaf node `int: number` or `float: percentage`  \n",
    "`max_feataures` max number of feature to consider `int: number`, `float: percentage` or `auto`, `sqrt`, `log2` or `None`    \n",
    "`max_leaf_nodes` max number of leafs. if `None`then unlimited number of leafs. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeClassifier(max_depth = 10, min_samples_split = 30, min_samples_leaf = 30).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_d_tree = pd.DataFrame(d_tree.feature_importances_.tolist(), columns = ['value']).set_index(cred.columns[:-1]).\\\n",
    "                            sort_values(by = ['value'], ascending = False)\n",
    "    \n",
    "varimp_d_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(d_tree, \n",
    "                                out_file='my_tree.dot',\n",
    "                                filled=True, rounded=True,\n",
    "                                feature_names = x_train.columns, \n",
    "                                class_names = ['yes','no'], \n",
    "                                special_characters=False)\n",
    "\n",
    "graph = graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assining out_file = None produces a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graph,) = pydot.graph_from_dot_file('my_tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#graph.write_png('my_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"my_tree.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob_tree = d_tree.predict_proba(x_test)\n",
    "predicted_prob_tree[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree/randomForest classifiers upon prediction return an array of two columns\n",
    "\n",
    "at each row the sum of the two values add up to 1. the first column is the probability of failure and the second column is the probability of success (given that failure is `0` and success is `1`)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_tree  = predicted_prob_tree[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_d_tree = [0 if i < 0.5 else 1 for i in y_prob_tree]\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_true = y_test, y_pred = predicted_d_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_prob_tree)\n",
    "AUC = auc(x = fpr, y = tpr )\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(fpr,tpr,label='AUC = {}'.format(AUC), color = 'purple')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC curve Tree Classifier')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_true = y_test , y_pred = predicted_d_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "# 8 cross validation\n",
    "\n",
    "the scoring paramtere <a href='http://scikit-learn.org/stable/modules/model_evaluation.html'>link</a>\n",
    "\n",
    "\n",
    "* cross validation is a method used for model validation to assess the behavior of the model for out-of-sample testing.   \n",
    "\n",
    "* there are many flavors to cross-validaion such as k-fold cross validation and Leave-One-Out cross validation. \n",
    "\n",
    "* the basic idea involves estimating several models to the same dataset but each time reshuffling the train and test sets. \n",
    "\n",
    "* the behavior of the model is then evaluated using a chose metric such as `log_loss` or `roc_curve` etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "`cross_val_score(estimator, \n",
    "                X, \n",
    "                y=None, \n",
    "                scoring=None, \n",
    "                cv=None, \n",
    "                n_jobs=1)`\n",
    "                \n",
    "                \n",
    "`estimator` the fitted model    \n",
    "`X` train set   \n",
    "`y` test set   \n",
    "`scoring` evaluation metric \n",
    "`cv` an integer (k-fold) or a cross-validation generator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(d_tree,\n",
    "                         X = cred.iloc[:,:-1], \n",
    "                         y = cred.iloc[:,-1],\n",
    "                         cv=5, \n",
    "                         scoring = 'roc_auc')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "the method `shuffleSplit()` is random permutation generator that yields indices to split data into training and test sets.\n",
    "\n",
    "\n",
    "`ShuffleSplit(n_splits=10,\n",
    "                test_size='default',\n",
    "                train_size=None, \n",
    "                random_state=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = ShuffleSplit(n_splits = 5, test_size = .3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(d_tree,\n",
    "                         cred.iloc[:,:-1],\n",
    "                         cred.iloc[:,-1], \n",
    "                         cv=cv_splits, \n",
    "                         scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "`cv_splits` which is an instance of the method `ShuffleSplit()` has an instance method `split` which is nothing but a generator, we can expand it using list and retrives the indeces of the train and test folds. \n",
    "\n",
    "`cv_splits` is already defined to have `n_splits=5`, `test_size=3` and `random_state=12` , we can extract the indeces using the method `split` as follows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_split = cv_splits.split(X = cred.iloc[:,:-1],\n",
    "                y = cred.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = list(manual_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "streamline the extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tree_roc(split_obj, df):\n",
    "    \n",
    "    '''  \n",
    "    split_obj: a ShuffleSplit.split() generator object defining k-fold train and test indeces in a DataFrame\n",
    "         \n",
    "    df: pandas DataFrame \n",
    "             \n",
    "    this method assumes the last column of df constitutes the dependent variable\n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize = (15,9))\n",
    "    lsp = list(split_obj)\n",
    "    folds = len(lsp)\n",
    "    index = folds -1\n",
    "    \n",
    "    auc_ = []\n",
    "    col_vec = []\n",
    "    while index > -1:\n",
    "\n",
    "        \n",
    "        x_train, x_test = df.iloc[lsp[index][0].tolist(),:-1], df.iloc[lsp[index][1].tolist(),:-1]\n",
    "        \n",
    "        y_train, y_test = df.iloc[lsp[index][0].tolist(),-1], df.iloc[lsp[index][1].tolist(),-1]\n",
    "        \n",
    "        pine = DecisionTreeClassifier(max_depth = 10, min_samples_split = 30, min_samples_leaf = 30).\\\n",
    "                                                                    fit(x_train, y_train)\n",
    "        predicted_prob = pine.predict_proba(x_test)\n",
    "        y_prob = predicted_prob[:,1].tolist()\n",
    "        \n",
    "        # ensuring no color redundency \n",
    "        col = np.random.randint(0,147)\n",
    "        if col in col_vec:\n",
    "            col = np.random.randint(0,147)\n",
    "        else:\n",
    "            col_vec.append(col)\n",
    "        \n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_prob)\n",
    "        auc_.append(round(auc(x = fpr, y = tpr),4))\n",
    "        plt.plot(fpr,tpr, color = list(mcolors.CSS4_COLORS.keys())[col])\n",
    "        index -= 1\n",
    "        \n",
    "        \n",
    "    plt.title('ROC curves for {}-fold cross validation'.format(folds))\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.xlabel('False positive rate')\n",
    "    names = list(map(lambda x,y: x+str(y), folds * ['fold '], list(range(1,folds+1))))\n",
    "    plt.legend(auc_ ,loc=\"best\", prop = {'size':15})\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    print('mean AUC for {}-fold cross validation: {}'.format(folds,round(np.mean(auc_),4)))\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "splits = cv_splits.split(cred.iloc[:,:-1],cred.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_tree_roc(splits, cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv_tree_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "\n",
    "# 9 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomForestClassifier(n_estimators=10,   \n",
    "                        criterion=’gini’,   \n",
    "                        max_depth=None,    \n",
    "                        min_samples_split=2,    \n",
    "                        min_samples_leaf=1,    \n",
    "                        min_weight_fraction_leaf=0.0,   \n",
    "                        max_features=’auto’,    \n",
    "                        max_leaf_nodes=None,     \n",
    "                        min_impurity_decrease=0.0,    \n",
    "                        min_impurity_split=None,     \n",
    "                        bootstrap=True,    \n",
    "                        oob_score=False,    \n",
    "                        n_jobs=1,    \n",
    "                        random_state=None,    \n",
    "                        verbose=0,    \n",
    "                        warm_start=False,    \n",
    "                        class_weight=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth = 3, min_samples_split = 30, min_samples_leaf = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "check variable importance for decision tree classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_d_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_rf = pd.DataFrame(rfc.feature_importances_, index = x_train.columns, columns = ['value']).\\\n",
    "                                                                sort_values(by = ['value'], ascending = True)\n",
    "varimp_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = .7\n",
    "ind = np.arange(varimp_rf.shape[0])\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.tick_params(axis='y', which='major', labelsize=15)\n",
    "plt.barh(ind ,varimp_rf['value'], width, color = 'deeppink' )\n",
    "plt.yticks(ind, varimp_rf.index)\n",
    "plt.title('RF parameter importance', fontdict = {'fontsize':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob_rf = rfc.predict_proba(x_test)\n",
    "y_prob_rf = predicted_prob_rf[:,1]\n",
    "\n",
    "predicted_thresh_rf = [0 if i < 0.5 else 1 for i in y_prob_rf]\n",
    "pd.DataFrame(confusion_matrix(y_true = y_test, y_pred = predicted_thresh_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_prob_rf)\n",
    "AUC = auc(x = fpr, y = tpr )\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(fpr,tpr,label='AUC = {}'.format(AUC), color = 'purple')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC curve RF classifier')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_true = y_test, y_pred = y_prob_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 9.1 Grid Search and paramter tuning\n",
    "\n",
    "* the principle behind grid search is to estimate the model using combinations of different parameters and find the combination that maximizes the reduction in error\n",
    "\n",
    "\n",
    "* grid search can be carried out manually for most models however randomForest (in both Python and R) has a dedicated method that can perform grid search\n",
    "\n",
    "\n",
    "to start define the grid parameters as a dictionary   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'n_estimators': [10,20,50],\n",
    "               'max_depth': [5,10,15,20,25],\n",
    "               'min_samples_split': [10,15,20,30],\n",
    "               'min_samples_leaf': [10,15,20,25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that we are passing the entire dataset\n",
    "\n",
    "rf_cv = GridSearchCV(rf, \n",
    "                     grid_params, \n",
    "                     cv=n_folds,  # cv_splits \n",
    "                     refit=True, \n",
    "                     scoring = 'roc_auc').fit(cred.iloc[:,:-1], cred.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.grid_scores_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(n_estimators = rf_cv.best_params_['n_estimators'],\n",
    "                                max_depth = rf_cv.best_params_['max_depth'], \n",
    "                                min_samples_split = rf_cv.best_params_['min_samples_split'], \n",
    "                                min_samples_leaf = rf_cv.best_params_['min_samples_leaf'])\n",
    "rf_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob_cv = rf_best.predict_proba(x_test)\n",
    "y_prob_cv = predicted_prob_cv[:,1]\n",
    "\n",
    "predicted_thresh_cv = [0 if i < 0.5 else 1 for i in y_prob_cv]\n",
    "pd.DataFrame(confusion_matrix(y_true = y_test, y_pred = predicted_thresh_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_prob_cv)\n",
    "AUC = auc(x = fpr, y = tpr )\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(fpr,tpr,label='AUC = {}'.format(AUC), color = 'purple')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC curve RF classifier')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_true = y_test, y_pred = y_prob_cv)log_loss(y_true = y_test, y_pred = y_prob_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improved log_loss !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
